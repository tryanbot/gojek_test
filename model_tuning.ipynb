{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "from catboost import *\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import ward, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train = pd.read_csv('data/train_v2.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('data/test_non_anomaly_v2.csv', parse_dates=['date'])\n",
    "y_train = train[['online_hours']]\n",
    "X_train = train.drop(['driver_id', 'day', 'date', 'online_hours', \n",
    "                      'holiday', 'next_holiday', 'prev_holiday'],axis=1)\n",
    "X_test = test.drop(['driver_id', 'day', 'date', 'online_hours', \n",
    "                      'holiday', 'next_holiday', 'prev_holiday'],axis=1)\n",
    "y_test = test[['online_hours']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset, X_test_subset, y_train_subset, y_test_subset = train_test_split(X_train, y_train, \n",
    "                                                                                test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xgboost_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train.values\n",
    "        self.y_train = y_train.values\n",
    "        self.x_test = x_test.values\n",
    "        self.y_test = y_test.values\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        booster_dict = {1:'gbtree', 2:'gblinear', 3:'dart'}\n",
    "        params = {'random_state':0, \n",
    "                  'subsample':1, \n",
    "                  'colsample_bytree':1, \n",
    "                  'colsample_bylevel':1}\n",
    "        \n",
    "        params['objective'] = 'reg:squarederror'\n",
    "        params['learning_rate'] = 0.1\n",
    "        params['n_estimators'] = 100\n",
    "        params['booster'] = booster_dict[int(param['booster'])]\n",
    "        params['gamma'] = param['gamma']\n",
    "        params['reg_alpha'] = param['reg_alpha']\n",
    "        params['reg_lambda'] = param['reg_lambda']\n",
    "        params['scale_pos_weight'] = param['scale_pos_weight']\n",
    "        params['base_score'] = param['base_score']\n",
    "        params['rate_drop'] = param['rate_drop']\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self,  \n",
    "                 booster, \n",
    "                 gamma, \n",
    "                 reg_alpha, \n",
    "                 reg_lambda, \n",
    "                 scale_pos_weight, \n",
    "                 base_score, \n",
    "                 rate_drop):\n",
    "\n",
    "        params = {}\n",
    "        params['learning_rate'] = 0.1\n",
    "        params['n_estimators'] = 100\n",
    "        params['booster'] = booster\n",
    "        params['gamma'] = gamma\n",
    "        params['reg_alpha'] = reg_alpha\n",
    "        params['reg_lambda'] = reg_lambda\n",
    "        params['scale_pos_weight'] = scale_pos_weight\n",
    "        params['base_score'] = base_score\n",
    "        params['rate_drop'] = rate_drop\n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        xgb_model = XGBRegressor(**params)\n",
    "        xgb_model.fit(self.x_train, self.y_train)\n",
    "        y_pred = xgb_model.predict(self.x_test)\n",
    "        predictions = [value for value in y_pred]\n",
    "        mse = mean_squared_error(self.y_test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return -1*rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | base_s... |  booster  |   gamma   | rate_drop | reg_alpha | reg_la... | scale_... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.543   \u001b[0m | \u001b[0m 20.85   \u001b[0m | \u001b[0m 2.441   \u001b[0m | \u001b[0m 0.005719\u001b[0m | \u001b[0m 0.3023  \u001b[0m | \u001b[0m 7.338   \u001b[0m | \u001b[0m 4.617   \u001b[0m | \u001b[0m 9.313   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-1.926   \u001b[0m | \u001b[95m 17.28   \u001b[0m | \u001b[95m 1.794   \u001b[0m | \u001b[95m 26.94   \u001b[0m | \u001b[95m 0.4192  \u001b[0m | \u001b[95m 34.26   \u001b[0m | \u001b[95m 10.22   \u001b[0m | \u001b[95m 43.91   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-3.156   \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m 2.341   \u001b[0m | \u001b[0m 20.87   \u001b[0m | \u001b[0m 0.5587  \u001b[0m | \u001b[0m 7.019   \u001b[0m | \u001b[0m 9.905   \u001b[0m | \u001b[0m 40.04   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.932   \u001b[0m | \u001b[0m 48.41   \u001b[0m | \u001b[0m 1.627   \u001b[0m | \u001b[0m 34.62   \u001b[0m | \u001b[0m 0.8764  \u001b[0m | \u001b[0m 44.73   \u001b[0m | \u001b[0m 4.252   \u001b[0m | \u001b[0m 1.953   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-3.427   \u001b[0m | \u001b[0m 8.492   \u001b[0m | \u001b[0m 2.756   \u001b[0m | \u001b[0m 4.917   \u001b[0m | \u001b[0m 0.4211  \u001b[0m | \u001b[0m 47.89   \u001b[0m | \u001b[0m 26.66   \u001b[0m | \u001b[0m 34.59   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-3.423   \u001b[0m | \u001b[0m 15.78   \u001b[0m | \u001b[0m 2.373   \u001b[0m | \u001b[0m 41.73   \u001b[0m | \u001b[0m 0.01829 \u001b[0m | \u001b[0m 37.51   \u001b[0m | \u001b[0m 49.44   \u001b[0m | \u001b[0m 37.41   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.424   \u001b[0m | \u001b[0m 14.02   \u001b[0m | \u001b[0m 2.579   \u001b[0m | \u001b[0m 5.161   \u001b[0m | \u001b[0m 0.4479  \u001b[0m | \u001b[0m 45.43   \u001b[0m | \u001b[0m 14.68   \u001b[0m | \u001b[0m 14.39   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-1.915   \u001b[0m | \u001b[95m 6.501   \u001b[0m | \u001b[95m 1.039   \u001b[0m | \u001b[95m 33.94   \u001b[0m | \u001b[95m 0.2116  \u001b[0m | \u001b[95m 13.28   \u001b[0m | \u001b[95m 24.58   \u001b[0m | \u001b[95m 2.668   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.933   \u001b[0m | \u001b[0m 28.71   \u001b[0m | \u001b[0m 1.293   \u001b[0m | \u001b[0m 29.47   \u001b[0m | \u001b[0m 0.6998  \u001b[0m | \u001b[0m 5.117   \u001b[0m | \u001b[0m 20.7    \u001b[0m | \u001b[0m 34.72   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.926   \u001b[0m | \u001b[0m 20.71   \u001b[0m | \u001b[0m 1.1     \u001b[0m | \u001b[0m 26.79   \u001b[0m | \u001b[0m 0.6638  \u001b[0m | \u001b[0m 25.74   \u001b[0m | \u001b[0m 47.23   \u001b[0m | \u001b[0m 29.33   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-1.916   \u001b[0m | \u001b[0m 45.17   \u001b[0m | \u001b[0m 1.275   \u001b[0m | \u001b[0m 6.964   \u001b[0m | \u001b[0m 0.8074  \u001b[0m | \u001b[0m 19.88   \u001b[0m | \u001b[0m 8.268   \u001b[0m | \u001b[0m 46.38   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-3.42    \u001b[0m | \u001b[0m 17.39   \u001b[0m | \u001b[0m 2.502   \u001b[0m | \u001b[0m 36.3    \u001b[0m | \u001b[0m 0.8833  \u001b[0m | \u001b[0m 31.18   \u001b[0m | \u001b[0m 37.55   \u001b[0m | \u001b[0m 17.44   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-3.422   \u001b[0m | \u001b[0m 13.5    \u001b[0m | \u001b[0m 2.792   \u001b[0m | \u001b[0m 21.4    \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 33.17   \u001b[0m | \u001b[0m 31.08   \u001b[0m | \u001b[0m 5.737   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-1.933   \u001b[0m | \u001b[0m 47.47   \u001b[0m | \u001b[0m 1.9     \u001b[0m | \u001b[0m 28.92   \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 11.85   \u001b[0m | \u001b[0m 45.17   \u001b[0m | \u001b[0m 28.68   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.429   \u001b[0m | \u001b[0m 0.1435  \u001b[0m | \u001b[0m 2.234   \u001b[0m | \u001b[0m 16.33   \u001b[0m | \u001b[0m 0.5271  \u001b[0m | \u001b[0m 44.3    \u001b[0m | \u001b[0m 17.86   \u001b[0m | \u001b[0m 45.43   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.917   \u001b[0m | \u001b[0m 5.528   \u001b[0m | \u001b[0m 1.038   \u001b[0m | \u001b[0m 34.93   \u001b[0m | \u001b[0m 0.2099  \u001b[0m | \u001b[0m 13.48   \u001b[0m | \u001b[0m 24.41   \u001b[0m | \u001b[0m 3.057   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-1.927   \u001b[0m | \u001b[0m 45.98   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 38.17   \u001b[0m | \u001b[0m 0.326   \u001b[0m | \u001b[0m 31.88   \u001b[0m | \u001b[0m 0.4241  \u001b[0m | \u001b[0m 43.75   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-1.92    \u001b[0m | \u001b[0m 30.64   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.57   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 11.5    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 49.13   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-1.92    \u001b[0m | \u001b[0m 16.4    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 23.57   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 20.76   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-1.926   \u001b[0m | \u001b[0m 28.71   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 4.959   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-1.926   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 16.48   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 41.8    \u001b[0m | \u001b[0m 32.86   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-1.948   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 20.19   \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-1.919   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-1.938   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-1.92    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "xt = xgboost_target(X_train_subset, y_train_subset, X_test_subset, y_test_subset)\n",
    "xgbBO = BayesianOptimization(xt.evaluate, {'booster' : (1, 3),\n",
    "                                            'gamma' : (0, 50),\n",
    "                                            'reg_alpha' : (0, 50),\n",
    "                                            'reg_lambda' : (0, 50),\n",
    "                                            'scale_pos_weight' : (0, 50),\n",
    "                                            'base_score' : (0, 50),\n",
    "                                            'rate_drop': (0, 1)},\n",
    "                            random_state = 1)\n",
    "\n",
    "xgbBO.maximize(init_points=15, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -1.914544397899434,\n",
       " 'params': {'base_score': 6.501428605913883,\n",
       "  'booster': 1.0387339157405941,\n",
       "  'gamma': 33.94177664699455,\n",
       "  'rate_drop': 0.21162811600005904,\n",
       "  'reg_alpha': 13.277332968611312,\n",
       "  'reg_lambda': 24.578657964016916,\n",
       "  'scale_pos_weight': 2.668127255854019}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbBO.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lgbm_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        params = {'boosting_type':'gbdt', 'class_weight':None, 'colsample_bytree':1.0, \n",
    "                  'importance_type':'split', 'learning_rate':0.1,\n",
    "                  'min_child_samples':20, 'min_split_gain':0.0, 'n_estimators':100, 'objective':None,\n",
    "                  'random_state':0, 'reg_alpha':0.0, 'reg_lambda':0.0, 'silent':True,\n",
    "                  'subsample':1.0, 'subsample_for_bin':200000, 'subsample_freq':0}\n",
    "        params['num_leaves'] = int(param['num_leaves'])\n",
    "        params['min_child_weight'] = int(param['min_child_weight'])\n",
    "        params['max_depth'] = int(param['max_depth'])\n",
    "        params['learning_rate'] = 0.1\n",
    "        params['min_data_in_bin'] = 1\n",
    "        params['min_data'] = 1\n",
    "        \n",
    "        params['min_child_samples'] = int(param['min_child_samples'])\n",
    "        params['bagging_fraction'] = param['bagging_fraction']\n",
    "        params['lambda_l1'] = param['lambda_l1']\n",
    "        params['lambda_l2'] = param['lambda_l2']\n",
    "\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, min_child_weight, max_depth, num_leaves,\n",
    "                min_child_samples, bagging_fraction, lambda_l1, lambda_l2):\n",
    "        params = {'num_leaves':num_leaves, \n",
    "                  'min_child_weight':min_child_weight, \n",
    "                  'max_depth':max_depth,\n",
    "                 'min_child_samples':min_child_samples,\n",
    "                 'bagging_fraction' : bagging_fraction,\n",
    "                 'lambda_l1' : lambda_l1,\n",
    "                 'lambda_l2' : lambda_l2}\n",
    "        \n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        lgbm_model = LGBMRegressor(**params)\n",
    "        lgbm_model.fit(self.x_train, self.y_train)\n",
    "        y_pred = lgbm_model.predict(self.x_test)\n",
    "        predictions = [value for value in y_pred]\n",
    "        mse = mean_squared_error(self.y_test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return -1*rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_ch... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.898   \u001b[0m | \u001b[0m 0.7754  \u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 0.2909  \u001b[0m | \u001b[0m 4.065   \u001b[0m | \u001b[0m 45.72   \u001b[0m | \u001b[0m 0.8973  \u001b[0m | \u001b[0m 10.65   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-2.056   \u001b[0m | \u001b[0m 0.6036  \u001b[0m | \u001b[0m 0.05147 \u001b[0m | \u001b[0m 0.4408  \u001b[0m | \u001b[0m 1.179   \u001b[0m | \u001b[0m 28.27   \u001b[0m | \u001b[0m 0.6527  \u001b[0m | \u001b[0m 17.53   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-1.893   \u001b[0m | \u001b[95m 0.8381  \u001b[0m | \u001b[95m 0.5909  \u001b[0m | \u001b[95m 0.02398 \u001b[0m | \u001b[95m 4.353   \u001b[0m | \u001b[95m 20.37   \u001b[0m | \u001b[95m 0.421   \u001b[0m | \u001b[95m 17.76   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.895   \u001b[0m | \u001b[0m 0.8466  \u001b[0m | \u001b[0m 0.4405  \u001b[0m | \u001b[0m 0.1569  \u001b[0m | \u001b[0m 4.268   \u001b[0m | \u001b[0m 41.21   \u001b[0m | \u001b[0m 0.3133  \u001b[0m | \u001b[0m 14.99   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.894   \u001b[0m | \u001b[0m 0.694   \u001b[0m | \u001b[0m 0.9364  \u001b[0m | \u001b[0m 0.976   \u001b[0m | \u001b[0m 5.034   \u001b[0m | \u001b[0m 46.11   \u001b[0m | \u001b[0m 0.8473  \u001b[0m | \u001b[0m 22.01   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.905   \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 0.6534  \u001b[0m | \u001b[0m 0.5578  \u001b[0m | \u001b[0m 3.169   \u001b[0m | \u001b[0m 19.0    \u001b[0m | \u001b[0m 0.4125  \u001b[0m | \u001b[0m 26.1    \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.895   \u001b[0m | \u001b[0m 0.6346  \u001b[0m | \u001b[0m 0.2918  \u001b[0m | \u001b[0m 0.4577  \u001b[0m | \u001b[0m 6.163   \u001b[0m | \u001b[0m 33.45   \u001b[0m | \u001b[0m 0.2907  \u001b[0m | \u001b[0m 17.51   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.894   \u001b[0m | \u001b[0m 0.7273  \u001b[0m | \u001b[0m 0.2054  \u001b[0m | \u001b[0m 0.2014  \u001b[0m | \u001b[0m 4.084   \u001b[0m | \u001b[0m 13.49   \u001b[0m | \u001b[0m 0.4887  \u001b[0m | \u001b[0m 21.3    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.895   \u001b[0m | \u001b[0m 0.8538  \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.6911  \u001b[0m | \u001b[0m 5.135   \u001b[0m | \u001b[0m 24.94   \u001b[0m | \u001b[0m 0.6715  \u001b[0m | \u001b[0m 20.29   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.056   \u001b[0m | \u001b[0m 0.7864  \u001b[0m | \u001b[0m 0.3258  \u001b[0m | \u001b[0m 0.4451  \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m 19.71   \u001b[0m | \u001b[0m 0.9719  \u001b[0m | \u001b[0m 15.38   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-1.904   \u001b[0m | \u001b[0m 0.8457  \u001b[0m | \u001b[0m 0.6505  \u001b[0m | \u001b[0m 0.7239  \u001b[0m | \u001b[0m 3.851   \u001b[0m | \u001b[0m 33.87   \u001b[0m | \u001b[0m 0.0763  \u001b[0m | \u001b[0m 8.265   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.056   \u001b[0m | \u001b[0m 0.5995  \u001b[0m | \u001b[0m 0.1519  \u001b[0m | \u001b[0m 0.1001  \u001b[0m | \u001b[0m 1.776   \u001b[0m | \u001b[0m 32.13   \u001b[0m | \u001b[0m 0.1959  \u001b[0m | \u001b[0m 47.84   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-1.958   \u001b[0m | \u001b[0m 0.8408  \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 0.7072  \u001b[0m | \u001b[0m 2.583   \u001b[0m | \u001b[0m 47.07   \u001b[0m | \u001b[0m 0.8408  \u001b[0m | \u001b[0m 37.68   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-1.895   \u001b[0m | \u001b[0m 0.7401  \u001b[0m | \u001b[0m 0.8421  \u001b[0m | \u001b[0m 0.7448  \u001b[0m | \u001b[0m 4.962   \u001b[0m | \u001b[0m 46.56   \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 21.47   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-1.898   \u001b[0m | \u001b[0m 0.7764  \u001b[0m | \u001b[0m 0.1964  \u001b[0m | \u001b[0m 0.1921  \u001b[0m | \u001b[0m 5.354   \u001b[0m | \u001b[0m 41.4    \u001b[0m | \u001b[0m 0.9724  \u001b[0m | \u001b[0m 43.29   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.903   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-1.912   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-1.904   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-1.89    \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 7.0     \u001b[0m | \u001b[95m 11.46   \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 32.08   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-1.912   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 41.13   \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-1.896   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 26.61   \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 36.07   \u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m-1.889   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 7.0     \u001b[0m | \u001b[95m 17.8    \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 24.3    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-2.056   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-1.912   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 25.33   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-1.898   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 35.09   \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lt = lgbm_target(X_train_subset, y_train_subset, X_test_subset, y_test_subset)\n",
    "lgbmBO = BayesianOptimization(lt.evaluate, {'min_child_weight': (0.01, 1),\n",
    "                                              'max_depth': (1, 7),\n",
    "                                              'num_leaves': (5, 50),\n",
    "                                            'min_child_samples' :(10,50),\n",
    "                                            'bagging_fraction' : (0.5,1),\n",
    "                                            'lambda_l1' : (0,1),\n",
    "                                            'lambda_l2' : (0,1)\n",
    "                                           }, \n",
    "                             random_state=3)\n",
    "\n",
    "lgbmBO.maximize(init_points=15, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -1.8888994232221157,\n",
       " 'params': {'bagging_fraction': 0.5,\n",
       "  'lambda_l1': 0.0,\n",
       "  'lambda_l2': 1.0,\n",
       "  'max_depth': 7.0,\n",
       "  'min_child_samples': 17.795932537903322,\n",
       "  'min_child_weight': 0.01,\n",
       "  'num_leaves': 24.30000086877875}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmBO.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rf_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        params = {\n",
    "            'max_depth' : 5,\n",
    "            'min_samples_split' : 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'min_weight_fraction_leaf': 0.0,\n",
    "            'min_impurity_decrease': 0.0\n",
    "            \n",
    "        }\n",
    "        params['max_depth'] = int(param['max_depth'])\n",
    "        params['min_samples_split'] = int(param['min_samples_split'])\n",
    "        params['min_samples_leaf'] = int(param['min_samples_leaf'])\n",
    "        params['min_weight_fraction_leaf'] = param['min_weight_fraction_leaf']\n",
    "        params['min_impurity_decrease'] = param['min_impurity_decrease']\n",
    "\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, max_depth, min_samples_split, min_samples_leaf,\n",
    "                min_weight_fraction_leaf, min_impurity_decrease):\n",
    "        params = {'max_depth':max_depth, \n",
    "                  'min_samples_split':min_samples_split, \n",
    "                  'min_samples_leaf':min_samples_leaf,\n",
    "                 'min_weight_fraction_leaf':min_weight_fraction_leaf,\n",
    "                 'min_impurity_decrease' : min_impurity_decrease}\n",
    "        \n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        rf_model = RandomForestRegressor(**params)\n",
    "        rf_model.fit(self.x_train, self.y_train)\n",
    "        y_pred = rf_model.predict(self.x_test)\n",
    "        predictions = [value for value in y_pred]\n",
    "        mse = mean_squared_error(self.y_test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return -1*rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_im... | min_sa... | min_sa... | min_we... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.363   \u001b[0m | \u001b[0m 5.957   \u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 18.09   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4465  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.15    \u001b[0m | \u001b[95m 9.067   \u001b[0m | \u001b[95m 0.1256  \u001b[0m | \u001b[95m 14.33   \u001b[0m | \u001b[95m 10.51   \u001b[0m | \u001b[95m 0.2204  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.39    \u001b[0m | \u001b[0m 1.269   \u001b[0m | \u001b[0m 0.4568  \u001b[0m | \u001b[0m 34.21   \u001b[0m | \u001b[0m 12.78   \u001b[0m | \u001b[0m 0.3381  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.184   \u001b[0m | \u001b[0m 6.318   \u001b[0m | \u001b[0m 0.02398 \u001b[0m | \u001b[0m 30.15   \u001b[0m | \u001b[0m 12.59   \u001b[0m | \u001b[0m 0.2076  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.202   \u001b[0m | \u001b[0m 3.552   \u001b[0m | \u001b[0m 0.6931  \u001b[0m | \u001b[0m 24.82   \u001b[0m | \u001b[0m 11.57   \u001b[0m | \u001b[0m 0.2723  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.372   \u001b[0m | \u001b[0m 8.023   \u001b[0m | \u001b[0m 0.3064  \u001b[0m | \u001b[0m 14.99   \u001b[0m | \u001b[0m 13.88   \u001b[0m | \u001b[0m 0.4682  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.164   \u001b[0m | \u001b[0m 9.784   \u001b[0m | \u001b[0m 0.6724  \u001b[0m | \u001b[0m 45.63   \u001b[0m | \u001b[0m 18.46   \u001b[0m | \u001b[0m 0.189   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.339   \u001b[0m | \u001b[0m 1.83    \u001b[0m | \u001b[0m 0.6534  \u001b[0m | \u001b[0m 30.1    \u001b[0m | \u001b[0m 13.62   \u001b[0m | \u001b[0m 0.1125  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.215   \u001b[0m | \u001b[0m 4.659   \u001b[0m | \u001b[0m 0.4689  \u001b[0m | \u001b[0m 17.12   \u001b[0m | \u001b[0m 12.92   \u001b[0m | \u001b[0m 0.2288  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.177   \u001b[0m | \u001b[0m 8.745   \u001b[0m | \u001b[0m 0.5863  \u001b[0m | \u001b[0m 17.76   \u001b[0m | \u001b[0m 12.78   \u001b[0m | \u001b[0m 0.2273  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.161   \u001b[0m | \u001b[0m 2.849   \u001b[0m | \u001b[0m 0.2014  \u001b[0m | \u001b[0m 28.13   \u001b[0m | \u001b[0m 10.87   \u001b[0m | \u001b[0m 0.2418  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.393   \u001b[0m | \u001b[0m 4.26    \u001b[0m | \u001b[0m 0.7077  \u001b[0m | \u001b[0m 38.6    \u001b[0m | \u001b[0m 16.91   \u001b[0m | \u001b[0m 0.3446  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.159   \u001b[0m | \u001b[0m 4.362   \u001b[0m | \u001b[0m 0.6681  \u001b[0m | \u001b[0m 20.29   \u001b[0m | \u001b[0m 15.73   \u001b[0m | \u001b[0m 0.1629  \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-2.104   \u001b[0m | \u001b[95m 5.006   \u001b[0m | \u001b[95m 0.06153 \u001b[0m | \u001b[95m 15.92   \u001b[0m | \u001b[95m 19.72   \u001b[0m | \u001b[95m 0.1153  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.355   \u001b[0m | \u001b[0m 7.223   \u001b[0m | \u001b[0m 0.6505  \u001b[0m | \u001b[0m 37.58   \u001b[0m | \u001b[0m 14.75   \u001b[0m | \u001b[0m 0.2983  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-2.339   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.428   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.354   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-3.123   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m-1.898   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 27.64   \u001b[0m | \u001b[95m 20.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-2.388   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-2.334   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 22.3    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-1.901   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-1.904   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-1.9     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 36.63   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "rf = rf_target(X_train_subset, y_train_subset, X_test_subset, y_test_subset)\n",
    "rfBO = BayesianOptimization(rf.evaluate, {'max_depth': (1, 10),\n",
    "                                              'min_samples_split': (10, 20),\n",
    "                                              'min_samples_leaf': (5, 50),\n",
    "                                            'min_weight_fraction_leaf' :(0,0.5),\n",
    "                                            'min_impurity_decrease' : (0,1)\n",
    "                                           }, \n",
    "                             random_state=3)\n",
    "\n",
    "rfBO.maximize(init_points=15, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -1.8979323609243068,\n",
       " 'params': {'max_depth': 10.0,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'min_samples_leaf': 27.643044588529033,\n",
       "  'min_samples_split': 20.0,\n",
       "  'min_weight_fraction_leaf': 0.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfBO.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class et_target :\n",
    "    def __init__(self, x_train, y_train, x_test, y_test) :\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def clean_param(self, param) :\n",
    "        params = {\n",
    "            'max_depth' : 5,\n",
    "            'min_samples_split' : 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'min_weight_fraction_leaf': 0.0,\n",
    "            'min_impurity_decrease': 0.0\n",
    "            \n",
    "        }\n",
    "        params['max_depth'] = int(param['max_depth'])\n",
    "        params['min_samples_split'] = int(param['min_samples_split'])\n",
    "        params['min_samples_leaf'] = int(param['min_samples_leaf'])\n",
    "        params['min_weight_fraction_leaf'] = param['min_weight_fraction_leaf']\n",
    "        params['min_impurity_decrease'] = param['min_impurity_decrease']\n",
    "\n",
    "        return params\n",
    "        \n",
    "    def evaluate(self, max_depth, min_samples_split, min_samples_leaf,\n",
    "                min_weight_fraction_leaf, min_impurity_decrease):\n",
    "        params = {'max_depth':max_depth, \n",
    "                  'min_samples_split':min_samples_split, \n",
    "                  'min_samples_leaf':min_samples_leaf,\n",
    "                 'min_weight_fraction_leaf':min_weight_fraction_leaf,\n",
    "                 'min_impurity_decrease' : min_impurity_decrease}\n",
    "        \n",
    "        params = self.clean_param(params)\n",
    "\n",
    "        et_model = ExtraTreesRegressor(**params)\n",
    "        et_model.fit(self.x_train, self.y_train)\n",
    "        y_pred = et_model.predict(self.x_test)\n",
    "        predictions = [value for value in y_pred]\n",
    "        mse = mean_squared_error(self.y_test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return -1*rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_im... | min_sa... | min_sa... | min_we... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.564   \u001b[0m | \u001b[0m 5.957   \u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 18.09   \u001b[0m | \u001b[0m 15.11   \u001b[0m | \u001b[0m 0.4465  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.259   \u001b[0m | \u001b[95m 9.067   \u001b[0m | \u001b[95m 0.1256  \u001b[0m | \u001b[95m 14.33   \u001b[0m | \u001b[95m 10.51   \u001b[0m | \u001b[95m 0.2204  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.376   \u001b[0m | \u001b[0m 1.269   \u001b[0m | \u001b[0m 0.4568  \u001b[0m | \u001b[0m 34.21   \u001b[0m | \u001b[0m 12.78   \u001b[0m | \u001b[0m 0.3381  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.283   \u001b[0m | \u001b[0m 6.318   \u001b[0m | \u001b[0m 0.02398 \u001b[0m | \u001b[0m 30.15   \u001b[0m | \u001b[0m 12.59   \u001b[0m | \u001b[0m 0.2076  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.337   \u001b[0m | \u001b[0m 3.552   \u001b[0m | \u001b[0m 0.6931  \u001b[0m | \u001b[0m 24.82   \u001b[0m | \u001b[0m 11.57   \u001b[0m | \u001b[0m 0.2723  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.602   \u001b[0m | \u001b[0m 8.023   \u001b[0m | \u001b[0m 0.3064  \u001b[0m | \u001b[0m 14.99   \u001b[0m | \u001b[0m 13.88   \u001b[0m | \u001b[0m 0.4682  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.27    \u001b[0m | \u001b[0m 9.784   \u001b[0m | \u001b[0m 0.6724  \u001b[0m | \u001b[0m 45.63   \u001b[0m | \u001b[0m 18.46   \u001b[0m | \u001b[0m 0.189   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.406   \u001b[0m | \u001b[0m 1.83    \u001b[0m | \u001b[0m 0.6534  \u001b[0m | \u001b[0m 30.1    \u001b[0m | \u001b[0m 13.62   \u001b[0m | \u001b[0m 0.1125  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.359   \u001b[0m | \u001b[0m 4.659   \u001b[0m | \u001b[0m 0.4689  \u001b[0m | \u001b[0m 17.12   \u001b[0m | \u001b[0m 12.92   \u001b[0m | \u001b[0m 0.2288  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.291   \u001b[0m | \u001b[0m 8.745   \u001b[0m | \u001b[0m 0.5863  \u001b[0m | \u001b[0m 17.76   \u001b[0m | \u001b[0m 12.78   \u001b[0m | \u001b[0m 0.2273  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.407   \u001b[0m | \u001b[0m 2.849   \u001b[0m | \u001b[0m 0.2014  \u001b[0m | \u001b[0m 28.13   \u001b[0m | \u001b[0m 10.87   \u001b[0m | \u001b[0m 0.2418  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.407   \u001b[0m | \u001b[0m 4.26    \u001b[0m | \u001b[0m 0.7077  \u001b[0m | \u001b[0m 38.6    \u001b[0m | \u001b[0m 16.91   \u001b[0m | \u001b[0m 0.3446  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.338   \u001b[0m | \u001b[0m 4.362   \u001b[0m | \u001b[0m 0.6681  \u001b[0m | \u001b[0m 20.29   \u001b[0m | \u001b[0m 15.73   \u001b[0m | \u001b[0m 0.1629  \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m-2.196   \u001b[0m | \u001b[95m 5.006   \u001b[0m | \u001b[95m 0.06153 \u001b[0m | \u001b[95m 15.92   \u001b[0m | \u001b[95m 19.72   \u001b[0m | \u001b[95m 0.1153  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.385   \u001b[0m | \u001b[0m 7.223   \u001b[0m | \u001b[0m 0.6505  \u001b[0m | \u001b[0m 37.58   \u001b[0m | \u001b[0m 14.75   \u001b[0m | \u001b[0m 0.2983  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-2.451   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.408   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.467   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m-1.874   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 27.93   \u001b[0m | \u001b[95m 20.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.379   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-3.349   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-2.464   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 23.7    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[95m 23      \u001b[0m | \u001b[95m-1.865   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 20.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-2.27    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-1.872   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 35.85   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "et = et_target(X_train_subset, y_train_subset, X_test_subset, y_test_subset)\n",
    "etBO = BayesianOptimization(et.evaluate, {'max_depth': (1, 10),\n",
    "                                              'min_samples_split': (10, 20),\n",
    "                                              'min_samples_leaf': (5, 50),\n",
    "                                            'min_weight_fraction_leaf' :(0,0.5),\n",
    "                                            'min_impurity_decrease' : (0,1)\n",
    "                                           }, \n",
    "                             random_state=3)\n",
    "\n",
    "etBO.maximize(init_points=15, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -1.8652185981184386,\n",
       " 'params': {'max_depth': 10.0,\n",
       "  'min_impurity_decrease': 0.0,\n",
       "  'min_samples_leaf': 5.0,\n",
       "  'min_samples_split': 20.0,\n",
       "  'min_weight_fraction_leaf': 0.0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etBO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
